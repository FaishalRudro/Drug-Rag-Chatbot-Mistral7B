{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceType":"datasetVersion","sourceId":14866590,"datasetId":9510203,"databundleVersionId":15728277}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import requests\nfrom bs4 import BeautifulSoup\nimport pandas as pd\n\n# Base URL for drug pages\nbase_url = \"https://www.drugs.com/\"\n\n# Function to extract drug information\ndef get_drug_info(drug_name, drug_url):\n    response = requests.get(drug_url)\n    \n    # Check for page existence (404 Not Found)\n    if response.status_code == 404:\n        print(f\"Page not found for {drug_name}. Skipping.\")\n        return None  # Skip this drug if the page is not found\n    \n    soup = BeautifulSoup(response.text, 'html.parser')\n\n    # Initialize variables\n    actual_drug_name = \"Not Available\"\n    generic_name = \"Not Available\"\n    drug_class = \"Not Available\"\n\n    try:\n        # Locate the drug name\n        drug_name_elem = soup.find('h1')\n        if drug_name_elem:\n            actual_drug_name = drug_name_elem.get_text(strip=True)\n\n            # Locate the section right under the drug name\n            sibling_elem = drug_name_elem.find_next('p')\n            if sibling_elem:\n                sibling_text = sibling_elem.get_text(separator=\" \").strip()\n\n                # Check for \"Generic name:\" and \"Drug class:\"\n                if \"Generic name:\" in sibling_text:\n                    generic_name = sibling_text.split(\"Generic name:\")[1].split(\"Drug class:\")[0].strip()\n                if \"Drug class:\" in sibling_text:\n                    drug_class = sibling_text.split(\"Drug class:\")[1].strip()\n                    # If multiple drug classes, split and join with commas\n                    drug_class = ', '.join([cls.strip() for cls in drug_class.split(',')])\n\n    except Exception as e:\n        print(f\"Error extracting drug details for {drug_name}: {e}\")\n\n    # Helper function to extract text from specific sections intelligently\n    def extract_specific_section(soup, section_titles):\n        section_data = ''\n        try:\n            # Find the first relevant section header that matches any of the section_titles\n            for title in section_titles:\n                section = soup.find('h2', string=lambda text: text and title.lower() in text.lower())\n                if section:\n                    # Collect all subsequent paragraphs that belong to this section\n                    for sibling in section.find_next_siblings():\n                        if sibling.name == 'h2':  # Stop when the next section starts\n                            break\n                        if sibling.name in ['p', 'ul', 'ol']:  # Capture paragraphs and lists\n                            section_data += sibling.get_text(strip=True) + '\\n'\n\n                    # Ensure the content is relevant (for example, only text related to dosage or side effects)\n                    if not section_data:\n                        section_data = \"Not Available\"\n                    return section_data.strip()\n\n        except Exception as e:\n            print(f\"Error extracting specific section: {e}\")\n        return \"Not Available\"\n\n    # Extract specific sections with intelligent matching\n    uses = extract_specific_section(soup, [f\"What is {drug_name}?\"])\n    warnings = extract_specific_section(soup, [\"Warnings\"])\n    pre_use_instructions = extract_specific_section(soup, [\"Before taking this medicine\"])\n\n    # Function to extract dosage information with missed dose and overdose integrated\n    def extract_dosage_info(soup):\n        dosage_info = extract_specific_section(soup, [\"How should I take\", \"Dosage\", \"Dosage form\", \"Dosing\"])\n\n        missed_dose_info = \"\"\n        overdose_info = \"\"\n\n        # Look for missed dose information and include it in the dosage\n        missed_dose_section = soup.find('h2', string=lambda text: text and \"missed dose\" in text.lower())\n        if missed_dose_section:\n            for sibling in missed_dose_section.find_next_siblings():\n                if sibling.name == 'h2':  # Stop when the next section starts\n                    break\n                if sibling.name in ['p', 'ul', 'ol']:\n                    missed_dose_info += sibling.get_text(strip=True) + '\\n'\n\n        # Look for overdose information and include it in the dosage\n        overdose_section = soup.find('h2', string=lambda text: text and \"overdose\" in text.lower())\n        if overdose_section:\n            for sibling in overdose_section.find_next_siblings():\n                if sibling.name == 'h2':  # Stop when the next section starts\n                    break\n                if sibling.name in ['p', 'ul', 'ol']:\n                    overdose_info += sibling.get_text(strip=True) + '\\n'\n\n        # Combine all dosage information, including missed dose and overdose info\n        full_dosage_info = dosage_info + \"\\n\" + missed_dose_info + \"\\n\" + overdose_info\n        return full_dosage_info.strip()\n\n    # Extract dosage and side effects with refined logic\n    dosage = extract_dosage_info(soup)\n\n    # Extract side effects in a previous format\n    side_effects = extract_specific_section(soup, [\"Side effects\"])\n\n    # If no specific side effects found, mark as Not Available\n    side_effects = side_effects if side_effects else \"Not Available\"\n\n    return {\n        \"Drug Name\": actual_drug_name,\n        \"Generic Name\": generic_name,\n        \"Drug Class\": drug_class,\n        \"Uses\": uses,\n        \"Warnings\": warnings,\n        \"Pre-Use Instructions\": pre_use_instructions,\n        \"Dosage\": dosage,\n        \"Side Effects\": side_effects\n    }\n\n# Main function to scrape data for drugs from an Excel file\ndef scrape_drugs_from_excel(excel_file):\n    df = pd.read_excel(excel_file)\n    \n    if 'Drug Name' not in df.columns:\n        print(\"Error: The Excel file must contain a column named 'Drug Name'.\")\n        return\n\n    # Prepare the list to hold all drug information\n    drug_data = []\n\n    for index, row in df.iterrows():\n        drug_name = row['Drug Name']\n        drug_url = f\"{base_url}{drug_name.lower().replace(' ', '-')}.html\"\n        print(f\"Scraping {drug_name} at {drug_url}...\")\n\n        # Fetch the drug info\n        try:\n            drug_info = get_drug_info(drug_name, drug_url)\n            if drug_info:  # Only proceed if data is valid\n                drug_data.append(drug_info)  # Add the extracted info to the list\n                print(f\"{drug_name} is done.\")\n            else:\n                print(f\"Skipped {drug_name} due to missing page.\")\n        except Exception as e:\n            print(f\"Failed to scrape {drug_name}. Error: {e}\")\n\n    # Convert the list of drug data to a DataFrame\n    drug_df = pd.DataFrame(drug_data)\n\n    # Write the DataFrame to an Excel file\n    output_file = \"drugs_info_from_excel.xlsx\"\n    drug_df.to_excel(output_file, index=False)\n    print(f\"Scraping completed. Data saved to '{output_file}'.\")\n\n# Run the scraper\nif __name__ == \"__main__\":\n    excel_file_path = r\"G:\\Faisal ahmed rudro\\487\\Rudro Data for Big Data.xlsx\"  # Update path to your Excel file\n    scrape_drugs_from_excel(excel_file_path)","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}